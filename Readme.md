# C++ Search Engine Project

A high-performance search engine implementation in C++ using advanced data structures including Trie, Max Heap, and TF-IDF scoring algorithm for efficient document retrieval and ranking.

## Features

- **Lightning-fast search** using Trie data structure
- **TF-IDF scoring** for document relevance ranking
- **Max Heap priority queue** for efficient result sorting
- **Memory-efficient implementation** with proper resource management
- **Interactive command-line interface**
- **Flexible dataset format support**

## Architecture

### Core Data Structures

1. **Trie (Prefix Tree)**: Stores all words from documents for O(m) lookup time
2. **Max Heap**: Priority queue for sorting search results by relevance score
3. **Document Map**: Efficient storage for document content
4. **Linked Lists**: Track word occurrences across documents

### Algorithm Overview

The search engine implements the TF-IDF (Term Frequency-Inverse Document Frequency) algorithm:

```
TF(term, doc) = (occurrences of term in doc) / (total terms in doc)
IDF(term) = log(total documents / documents containing term)
Score(term, doc) = TF(term, doc) Ã— IDF(term)
```

## Quick Start

### 1. Build the Project

```bash
# Clone or download the project
# Navigate to project directory

# Build the search engine
make

# Or build with debug information
make debug

# Or build optimized release version
make release
```

### 2. Create Sample Dataset

```bash
# Generate sample dataset file
make sample_data
```

### 3. Run the Search Engine

```bash
# Basic usage
./search_engine -d sample_dataset.txt -k 5

# The program will initialize and provide an interactive search prompt
```

### 4. Interactive Usage

Once running, you can enter search queries:

```
Search> programming languages
Search> data structures algorithms
Search> C++ development
Search> quit  # to exit
```

## Command Line Options

```bash
./search_engine -d <dataset_file> -k <num_results>
```

- `-d <file>`: Path to the dataset file (required)
- `-k <number>`: Number of top results to display (required)

## Dataset Format

The dataset file should use tab-separated values:

```
<document_id><TAB><document_content>
```

Example:
```
0	Welcome to the world of programming and software development
1	C++ is a powerful programming language for system development
2	Search engines use data structures like trie and heap for efficiency
```

## ğŸ“‚ Project Structure

```
SearchEngine/
â”‚
â”œâ”€â”€ ğŸ“„ main.cpp                 # Main application entry point
â”œâ”€â”€ ğŸ“„ SearchEngine.h           # Header file with class declarations
â”œâ”€â”€ ğŸ“„ SearchEngine.cpp         # Implementation of search engine logic
â”œâ”€â”€ ğŸ“„ Makefile                 # Build configuration
â”œâ”€â”€ ğŸ“„ README.md                # Project documentation
â”œâ”€â”€ ğŸ“„ sample_dataset.txt       # Sample data (generated by make sample_data)
â”œâ”€â”€ ğŸ“„ .gitignore               # Git ignore rules
â”‚
â””â”€â”€ ğŸ“ .vscode/                 # VS Code configuration (optional)
    â”œâ”€â”€ ğŸ“„ c_cpp_properties.json  # IntelliSense settings
    â”œâ”€â”€ ğŸ“„ tasks.json             # Build tasks
    â””â”€â”€ ğŸ“„ launch.json            # Debug configuration
```

## Advanced Usage

### Memory Leak Detection

```bash
# Check for memory leaks with Valgrind
make memcheck
```

### Performance Testing

```bash
# Create larger datasets for performance testing
# The engine can handle thousands of documents efficiently
```

### Custom Datasets

Create your own dataset file following the format:
```
0	Your first document content here
1	Second document with different content
2	More documents with various topics and keywords
```

## Technical Specifications

### Performance Characteristics

- **Search Time**: O(m + k log n) where m = query length, k = results, n = documents
- **Index Build Time**: O(d Ã— w) where d = documents, w = average words per document
- **Memory Usage**: O(vocabulary_size + total_word_occurrences)

### Key Features

1. **Efficient Word Lookup**: Trie structure provides O(word_length) search time
2. **Relevance Scoring**: TF-IDF algorithm ranks documents by relevance
3. **Memory Management**: Proper cleanup prevents memory leaks
4. **Scalability**: Can handle large document collections efficiently

## Code Structure Highlights

### Trie Implementation
```cpp
class TrieNode {
    char character;
    TrieNode* child;    // First child
    TrieNode* sibling;  // Next sibling (space-efficient)
    ListNode* documents; // Documents containing this word
};
```

### Max Heap for Results
```cpp
class MaxHeap {
    void heapifyUp(int index);
    void heapifyDown(int index);
    void insert(int doc_id, double score);
    HeapNode extractMax();
};
```

### TF-IDF Calculation
```cpp
double calculateTFIDF(const string& word, int doc_id) {
    double tf = calculateTF(word, doc_id);
    double idf = calculateIDF(word);
    return tf * idf;
}
```

## Building and Development

### Prerequisites

- C++11 compatible compiler (g++, clang++)
- Make utility
- Optional: Valgrind for memory debugging

### Build Targets

```bash
make            # Default build
make clean      # Clean object files
make debug      # Debug build with symbols
make release    # Optimized release build
make test       # Build and prepare test environment
make help       # Show all available targets
```

## Extending the Search Engine

### Possible Enhancements

1. **Stemming**: Implement word normalization
2. **Stop Words**: Filter common words
3. **Phrase Search**: Support for exact phrase matching
4. **Boolean Queries**: AND, OR, NOT operators
5. **Fuzzy Matching**: Handle typos and similar words
6. **Persistent Index**: Save/load prebuilt indices
7. **Multi-threading**: Parallel document processing
8. **Web Interface**: REST API for remote access

### Adding New Features

The modular design makes it easy to extend:

```cpp
// Add new scoring algorithms
double customScoring(const string& word, int doc_id) {
    // Your custom implementation
}

// Add new data structures
class InvertedIndex {
    // Alternative indexing approach
};
```

## Performance Tips

1. **Large Datasets**: Consider memory constraints for very large collections
2. **Query Optimization**: Cache frequently searched terms
3. **Index Optimization**: Preprocess common queries
4. **Memory Tuning**: Adjust heap sizes based on available RAM

## Troubleshooting

### Common Issues

1. **File Not Found**: Ensure dataset file path is correct
2. **Memory Errors**: Check dataset format (tab-separated)
3. **Build Errors**: Verify C++11 compiler availability
4. **Slow Performance**: Consider optimizing dataset size

### Debugging

```bash
# Build with debug symbols
make debug

# Run with GDB
gdb ./search_engine
(gdb) run -d sample_dataset.txt -k 5

# Check memory usage
make memcheck
```

## Acknowledgments

- Based on classical information retrieval concepts
- Inspired by search engine architecture principles
- Uses standard computer science algorithms and data structures